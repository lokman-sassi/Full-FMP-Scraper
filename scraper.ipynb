{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16f3a1f-7df4-47ad-9888-281bd16cd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing selenium necessary packages, here i'm working with chrome driver\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.service import Service as ChromeService \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# BeautifulSoup for parsing HTML\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff40a3d-8e28-41ed-a35c-053b5d19d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#city = \"djelfa\" chosen because it's nearly the center of Algeria, and it's the best option to scrap data with a big radius !\n",
    "#Djelfa code in url = 112237105459123\n",
    "base_url = \"https://web.facebook.com/marketplace/112237105459123/propertyforsale?\"\n",
    "\n",
    "# base_url = \"https://web.facebook.com/marketplace/constantine/propertyforsale/?\" for constantine\n",
    "# base_url = \"https://web.facebook.com/marketplace/oran/propertyforsale/?\" for oran\n",
    "\n",
    "sorting = \"price_descend\"\n",
    "#You can add another criteria to the url depending on your needs\n",
    "#minPrice = 18000000\n",
    "#maxPrice = ?\n",
    "#longitude = ?\n",
    "#latitude = ?\n",
    "\n",
    "#consider changing the url as your needs\n",
    "url = f\"{base_url}&sortBy={sorting}&radius=250&_rdc=1&_rdr\"\n",
    "\n",
    "# Working with selenium headless browser\n",
    "options = webdriver.ChromeOptions() \n",
    "options.headless = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e17a56-98d4-4913-9492-fa3b1a69200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that stores the announcements in the data base\n",
    "def save_to_database(records):\n",
    "    client = pymongo.MongoClient('mongodb://localhost:27017')\n",
    "    mydb = client[\"Real-Estate\"]\n",
    "    information = mydb.RealEstateListing\n",
    "    \n",
    "    if information.count_documents({}) == 0:  # Check if the collection is empty\n",
    "        information.insert_many(records)\n",
    "    else:\n",
    "        for record in records:\n",
    "            existing_listing = information.find_one({\"Title\": record[\"Title\"], \"Price\": record[\"Price\"], \"Location\": record[\"Location\"]})\n",
    "            \n",
    "            if existing_listing:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                information.insert_one(record)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# A function that closes the Facebook popup login windows\n",
    "def close_login_page():\n",
    "    try:\n",
    "        popup_close_button = driver.find_element(By.XPATH, \"//div[@class='x92rtbv x10l6tqk x1tk7jg1 x1vjfegm']\")\n",
    "        popup_close_button.click()\n",
    "\n",
    "        # Wait for the popup windows to close\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "\n",
    "def next_image():\n",
    "    try:\n",
    "        next_image_button = driver.find_element(By.XPATH, \"//div[@aria-label='View next image']\")\n",
    "        next_image_button.click()\n",
    "\n",
    "        # Wait for the image to be shown\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Check if the new image source is different from the first one\n",
    "        new_image_source = driver.find_element(By.XPATH, \"//img\").get_attribute(\"src\")\n",
    "        return new_image_source\n",
    "    except NoSuchElementException:\n",
    "        return None\n",
    "\n",
    "\n",
    "# A function to scroll to the bottom of the page\n",
    "def scroll_to_bottom(driver):\n",
    "    close_login_page()\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(6)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "\n",
    "def remove_additional_information(text):\n",
    "    toBeRemoved = [\"[hidden information]\", \"See less\"]\n",
    "    for word in toBeRemoved:\n",
    "        text = text.replace(word, '')     \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1542b-0729-4ade-9f16-b7b61dd8d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location facebook marketPlace is approximative\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options) \n",
    "driver.get(url)\n",
    "\n",
    "close_login_page()\n",
    "\n",
    "# Scroll to the bottom of the page to load all content\n",
    "scroll_to_bottom(driver)\n",
    "\n",
    "# JavaScript to remove the Facebook banner from the DOM\n",
    "script = \"\"\"\n",
    "var banner = document.querySelector('div.x78zum5.xdt5ytf.x2lah0s.x193iq5w.x2bj2ny.x1ey2m1c.xayqjjm.x9f619.xds687c.x1xy6bms.xn6708d.x1s14bel.x1ye3gou.xixxii4.x17qophe.x1u8a7rm');\n",
    "if (banner) {\n",
    "    banner.parentNode.removeChild(banner);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the JavaScript with Selenium\n",
    "driver.execute_script(script)\n",
    "\n",
    "\n",
    "# Waiting for all the elements to be visible\n",
    "wait = WebDriverWait(driver, 5|0)\n",
    "parent_elements = wait.until(EC.visibility_of_all_elements_located((By.XPATH, \"//a[@class='x1i10hfl xjbqb8w x1ejq31n xd10rxx x1sy0etr x17r0tee x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1heor9g x1sur9pj xkrqix3 x1lku1pv']\")))\n",
    "\n",
    "# Scraping data from each element and putting them in a list\n",
    "listings_data = [] \n",
    "\n",
    "# Collecting posts links firstly\n",
    "parent_links = [parent_element.get_attribute(\"href\") for parent_element in parent_elements]\n",
    "print(len(parent_links))\n",
    "# Iterate over links to visit each page separately\n",
    "\n",
    "try:\n",
    "    for listing_link in parent_links: \n",
    "        driver.get(listing_link)\n",
    "        time.sleep(3)\n",
    "        close_login_page()\n",
    "        try:\n",
    "            driver.execute_script(\"window.scrollBy(0, 300);\")\n",
    "            time.sleep(1)\n",
    "            listing_description_element = driver.find_element(By.XPATH, \".//div[@class='xz9dl7a x4uap5 xsag5q8 xkhd6sd x126k92a']\")\n",
    "            see_more_button = None\n",
    "            try:\n",
    "                see_more_button = listing_description_element.find_element(By.XPATH, \".//span[contains(text(), 'See more')]\")\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            if see_more_button:\n",
    "                see_more_button.click()\n",
    "                time.sleep(3)\n",
    "    \n",
    "            listing_description = listing_description_element.text.strip()\n",
    "            \n",
    "            if not listing_description:\n",
    "                listing_description = \"Description not available\"\n",
    "\n",
    "            cleaned_description = listing_description.replace('\\n', '')\n",
    "            description = remove_additional_information(cleaned_description)\n",
    "    \n",
    "            listing_price = driver.find_element(By.XPATH, \".//span[@class='x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x676frb x1lkfr7t x1lbecb7 x1s688f xzsf02u']\").text\n",
    "            listing_title = driver.find_element(By.XPATH, \".//span[@class='x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x14z4hjw x3x7a5m xngnso2 x1qb5hxa x1xlr1w8 xzsf02u']\").text\n",
    "            listing_title = remove_additional_information(listing_title)\n",
    "            listing_location = driver.find_element(By.XPATH, \".//span[@class='x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x3x7a5m x6prxxf xvq8zen xo1l8bm xzsf02u x1yc453h']\").text \n",
    "            listing_image_elements = driver.find_elements(By.XPATH, \".//img\")\n",
    "            images_data = []\n",
    "            first_image_source = listing_image_elements[0].get_attribute(\"src\")\n",
    "            images_data.append(first_image_source)  # Append the first image source\n",
    "    \n",
    "            while True:\n",
    "                new_image_source = next_image()\n",
    "                if new_image_source and new_image_source != first_image_source:\n",
    "                    images_data.append(new_image_source)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "        \n",
    "        temporary_listings_data = { \n",
    "            \"Title\": listing_title,\n",
    "            \"Price\": listing_price,\n",
    "            \"Location\": listing_location,\n",
    "            \"Description\": description,\n",
    "            \"Images\": images_data,\n",
    "            \"Source\": \"Facebook MarketPlace\",\n",
    "            \"Date\": None,\n",
    "            \"Link\": listing_link,\n",
    "            \"Category\": None,\n",
    "            \"Surface\": None,\n",
    "        } \n",
    "        # Save each listing immediately\n",
    "        save_to_database([temporary_listings_data])\n",
    "        \n",
    "        listings_data.append(temporary_listings_data) \n",
    "        print(temporary_listings_data)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    \n",
    "    # Save any scraped listings before exiting\n",
    "    save_to_database(listings_data)\n",
    "        \n",
    "finally:\n",
    "    save_to_database(listings_data)\n",
    "    print(\"Scraped items: \", len(listings_data))\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
